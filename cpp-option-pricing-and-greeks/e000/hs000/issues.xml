<?xml version='1.0' encoding='UTF-8'?>

<bag xmlns:boolean="http://www.w3.org/2001/XMLSchema#boolean" xmlns:float="http://www.w3.org/2001/XMLSchema#float" xmlns:int="http://www.w3.org/2001/XMLSchema#int" xmlns:unsignedInt="http://www.w3.org/2001/XMLSchema#unsignedInt" xmlns:unsignedLong="http://www.w3.org/2001/XMLSchema#unsignedLong" int:version="16">
 <issues>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_div</id>
   <int:severity>1</int:severity>
   <text>div_issue_text</text>
   <title>Unoptimized floating point operation processing possible</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_sqrt_c</id>
     <text>add_sqrt_text</text>
     <title>Enable the use of approximate sqrt instructions </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_system_functions</id>
   <int:severity>1</int:severity>
   <text>System function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; may prevent the compiler from vectorizing the loop. </text>
   <title>System function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_system_functions_move_c</id>
     <text>Typically system function or subroutine calls cannot be auto-vectorized; even a print statement is sufficient to prevent vectorization. To fix: Avoid using system function calls in loops. </text>
     <title>Remove system function call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>75</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_system_functions</id>
   <int:severity>1</int:severity>
   <text>System function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; may prevent the compiler from vectorizing the loop. </text>
   <title>System function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_system_functions_move_c</id>
     <text>Typically system function or subroutine calls cannot be auto-vectorized; even a print statement is sufficient to prevent vectorization. To fix: Avoid using system function calls in loops. </text>
     <title>Remove system function call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>75</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>75</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>76</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_system_functions</id>
   <int:severity>1</int:severity>
   <text>System function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; may prevent the compiler from vectorizing the loop. </text>
   <title>System function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_system_functions_move_c</id>
     <text>Typically system function or subroutine calls cannot be auto-vectorized; even a print statement is sufficient to prevent vectorization. To fix: Avoid using system function calls in loops. </text>
     <title>Remove system function call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>76</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>76</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_fma</id>
   <int:severity>1</int:severity>
   <text>Your current hardware supports the AVX2 instruction set architecture (ISA), which enables the use of fused multiply-add (FMA) instructions. Improve performance by utilizing FMA instructions. </text>
   <title>Potential underutilization of FMA instructions </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_fma_target_avx2_isa_c</id>
     <text>Although static analysis presumes the loop may benefit from FMA instructions available with the AVX2 ISA, no AVX2-specific code executed for this loop. To fix: Use the &lt;div class=&quot;inplace_sample&quot;&gt;xCORE-AVX2&lt;/div&gt; compiler option to generate AVX2-specific code, or the &lt;div class=&quot;inplace_sample&quot;&gt;axCORE-AVX2&lt;/div&gt; compiler option to enable multiple, feature-specific, auto-dispatch code generation, including AVX2. &lt;table&gt; &lt;tr&gt; &lt;th&gt; Windows* OS &lt;/th&gt; &lt;th&gt; Linux* OS &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/QxCORE-AVX2 or /QaxCORE-AVX2&lt;/td&gt; &lt;td&gt;-xCORE-AVX2 or -axCORE-AVX2&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More: &lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-2D881A91-C5D7-4DDD-84B1-FB9D0D597F4D.htm&quot;&gt;ax, Qax&lt;/a&gt;; &lt;a href=&quot;C++/17/index.htm#GUID-09734487-1819-4C1E-B314-2497F2B64C45.htm&quot;&gt;x, Qx&lt;/a&gt;
&lt;li&gt;&lt;em&gt;Code Generation Options&lt;/em&gt; in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/overview.html&quot;&gt;Intel&amp;reg; C++ Compiler 16.0 User and Reference Guide&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/architecture-and-technology/avx-512-solution-brief.html&quot;&gt;Compiling for the Intel&amp;reg; Xeon Phi&amp;trade; processor x200 and the Intel&amp;reg; AVX-512 ISA&lt;/a&gt; and &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Target the AVX2 ISA </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>81</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_fma</id>
   <int:severity>1</int:severity>
   <text>Your current hardware supports the AVX2 instruction set architecture (ISA), which enables the use of fused multiply-add (FMA) instructions. Improve performance by utilizing FMA instructions. </text>
   <title>Potential underutilization of FMA instructions </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_fma_target_avx2_isa_c</id>
     <text>Although static analysis presumes the loop may benefit from FMA instructions available with the AVX2 ISA, no AVX2-specific code executed for this loop. To fix: Use the &lt;div class=&quot;inplace_sample&quot;&gt;xCORE-AVX2&lt;/div&gt; compiler option to generate AVX2-specific code, or the &lt;div class=&quot;inplace_sample&quot;&gt;axCORE-AVX2&lt;/div&gt; compiler option to enable multiple, feature-specific, auto-dispatch code generation, including AVX2. &lt;table&gt; &lt;tr&gt; &lt;th&gt; Windows* OS &lt;/th&gt; &lt;th&gt; Linux* OS &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/QxCORE-AVX2 or /QaxCORE-AVX2&lt;/td&gt; &lt;td&gt;-xCORE-AVX2 or -axCORE-AVX2&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More: &lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-2D881A91-C5D7-4DDD-84B1-FB9D0D597F4D.htm&quot;&gt;ax, Qax&lt;/a&gt;; &lt;a href=&quot;C++/17/index.htm#GUID-09734487-1819-4C1E-B314-2497F2B64C45.htm&quot;&gt;x, Qx&lt;/a&gt;
&lt;li&gt;&lt;em&gt;Code Generation Options&lt;/em&gt; in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/overview.html&quot;&gt;Intel&amp;reg; C++ Compiler 16.0 User and Reference Guide&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/architecture-and-technology/avx-512-solution-brief.html&quot;&gt;Compiling for the Intel&amp;reg; Xeon Phi&amp;trade; processor x200 and the Intel&amp;reg; AVX-512 ISA&lt;/a&gt; and &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/advisor-vectorization-resources.html&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Target the AVX2 ISA </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>83</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_div</id>
   <int:severity>1</int:severity>
   <text>div_issue_text</text>
   <title>Unoptimized floating point operation processing possible</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_sqrt_c</id>
     <text>add_sqrt_text</text>
     <title>Enable the use of approximate sqrt instructions </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_system_functions</id>
   <int:severity>1</int:severity>
   <text>System function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; may prevent the compiler from vectorizing the loop. </text>
   <title>System function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_system_functions_move_c</id>
     <text>Typically system function or subroutine calls cannot be auto-vectorized; even a print statement is sufficient to prevent vectorization. To fix: Avoid using system function calls in loops. </text>
     <title>Remove system function call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_div</id>
   <int:severity>1</int:severity>
   <text>div_issue_text</text>
   <title>Unoptimized floating point operation processing possible</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_sqrt_c</id>
     <text>add_sqrt_text</text>
     <title>Enable the use of approximate sqrt instructions </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_system_functions</id>
   <int:severity>1</int:severity>
   <text>System function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; may prevent the compiler from vectorizing the loop. </text>
   <title>System function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_system_functions_move_c</id>
     <text>Typically system function or subroutine calls cannot be auto-vectorized; even a print statement is sufficient to prevent vectorization. To fix: Avoid using system function calls in loops. </text>
     <title>Remove system function call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>94</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_system_functions</id>
   <int:severity>1</int:severity>
   <text>System function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; may prevent the compiler from vectorizing the loop. </text>
   <title>System function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_system_functions_move_c</id>
     <text>Typically system function or subroutine calls cannot be auto-vectorized; even a print statement is sufficient to prevent vectorization. To fix: Avoid using system function calls in loops. </text>
     <title>Remove system function call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>94</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>94</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_register_pressure</id>
   <int:severity>3</int:severity>
   <text>Possible register &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;spilling&lt;/a&gt; was detected and all vector registers are in use. This may negatively impact performance, because the spilled variable must be loaded to and unloaded from main memory. Improve performance by decreasing vector &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;register pressure&lt;/a&gt;. </text>
   <title>Vector register spilling possible </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_registers_pressure_split_loop_c</id>
     <text>Possible register &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;spilling&lt;/a&gt; along with high vector &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;register pressure&lt;/a&gt; is preventing effective vectorization. To fix: Use a &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;directive&lt;/a&gt; or rewrite your code to distribute the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt;. This can decrease register pressure as well as enable software pipelining and improve both instruction and data cache use. &lt;/br&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; #pragma distribute_point &lt;/td&gt; &lt;td&gt; !DIR$ DISTRIBUTE POINT &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;a href=&quot;C++/17/index.htm#GUID-03B94EAB-70E2-4B45-B275-D73FD76961A0.htm&quot;&gt;distribute_point&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/release-notes/intel-c-compiler-160-for-linux-release-notes-for-intel-parallel-studio-xe-2016.html&quot;&gt;Intel&amp;reg; C++ Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;strong&gt;Fortran&lt;/strong&gt;: &lt;a href=&quot;Fortran/17/index.htm#GUID-759F460A-1FF1-44AC-B64C-910D8C57BB1B.htm&quot;&gt;DISTRIBUTE POINT&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/release-notes/intel-fortran-compiler-160-for-linux-release-notes-for-intel-parallel-studio-xe-2016.html&quot;&gt;Intel&amp;reg; Fortran Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/pragmas.html&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/3d-isotropic-acoustic-finite-difference-wave-equation-code-a-many-core-processor.html&quot;&gt;3D Finite Differences on Multi-core Processors&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Split loop into smaller loops </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>106</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>106</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>106</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>107</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_register_pressure</id>
   <int:severity>3</int:severity>
   <text>Possible register &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;spilling&lt;/a&gt; was detected and all vector registers are in use. This may negatively impact performance, because the spilled variable must be loaded to and unloaded from main memory. Improve performance by decreasing vector &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;register pressure&lt;/a&gt;. </text>
   <title>Vector register spilling possible </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_registers_pressure_split_loop_c</id>
     <text>Possible register &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;spilling&lt;/a&gt; along with high vector &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;register pressure&lt;/a&gt; is preventing effective vectorization. To fix: Use a &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;directive&lt;/a&gt; or rewrite your code to distribute the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt;. This can decrease register pressure as well as enable software pipelining and improve both instruction and data cache use. &lt;/br&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; #pragma distribute_point &lt;/td&gt; &lt;td&gt; !DIR$ DISTRIBUTE POINT &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;a href=&quot;C++/17/index.htm#GUID-03B94EAB-70E2-4B45-B275-D73FD76961A0.htm&quot;&gt;distribute_point&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/release-notes/intel-c-compiler-160-for-linux-release-notes-for-intel-parallel-studio-xe-2016.html&quot;&gt;Intel&amp;reg; C++ Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;strong&gt;Fortran&lt;/strong&gt;: &lt;a href=&quot;Fortran/17/index.htm#GUID-759F460A-1FF1-44AC-B64C-910D8C57BB1B.htm&quot;&gt;DISTRIBUTE POINT&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/release-notes/intel-fortran-compiler-160-for-linux-release-notes-for-intel-parallel-studio-xe-2016.html&quot;&gt;Intel&amp;reg; Fortran Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/pragmas.html&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/3d-isotropic-acoustic-finite-difference-wave-equation-code-a-many-core-processor.html&quot;&gt;3D Finite Differences on Multi-core Processors&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Split loop into smaller loops </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>109</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>109</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>109</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>110</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_register_pressure</id>
   <int:severity>3</int:severity>
   <text>Possible register &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;spilling&lt;/a&gt; was detected and all vector registers are in use. This may negatively impact performance, because the spilled variable must be loaded to and unloaded from main memory. Improve performance by decreasing vector &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;register pressure&lt;/a&gt;. </text>
   <title>Vector register spilling possible </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_registers_pressure_split_loop_c</id>
     <text>Possible register &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;spilling&lt;/a&gt; along with high vector &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;register pressure&lt;/a&gt; is preventing effective vectorization. To fix: Use a &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;directive&lt;/a&gt; or rewrite your code to distribute the &lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;source loop&lt;/a&gt;. This can decrease register pressure as well as enable software pipelining and improve both instruction and data cache use. &lt;/br&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/advisor/user-guide/current/glossary.html&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; #pragma distribute_point &lt;/td&gt; &lt;td&gt; !DIR$ DISTRIBUTE POINT &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;a href=&quot;C++/17/index.htm#GUID-03B94EAB-70E2-4B45-B275-D73FD76961A0.htm&quot;&gt;distribute_point&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/release-notes/intel-c-compiler-160-for-linux-release-notes-for-intel-parallel-studio-xe-2016.html&quot;&gt;Intel&amp;reg; C++ Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;strong&gt;Fortran&lt;/strong&gt;: &lt;a href=&quot;Fortran/17/index.htm#GUID-759F460A-1FF1-44AC-B64C-910D8C57BB1B.htm&quot;&gt;DISTRIBUTE POINT&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/release-notes/intel-fortran-compiler-160-for-linux-release-notes-for-intel-parallel-studio-xe-2016.html&quot;&gt;Intel&amp;reg; Fortran Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/current/pragmas.html&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/articles/technical/3d-isotropic-acoustic-finite-difference-wave-equation-code-a-many-core-processor.html&quot;&gt;3D Finite Differences on Multi-core Processors&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Split loop into smaller loops </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>111</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>113</unsignedLong:rowKey>
  </issue>
 </issues>
 <traits>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>15</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>18</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>19</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>48</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>49</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>50</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>52</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>54</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>54</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>59</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>59</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>60</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>60</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>61</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>61</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>155</int:fieldId>
   <int:id>4</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>148</int:fieldId>
   <int:id>5</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>62</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>63</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>63</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>64</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>64</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>66</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>66</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>67</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>67</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>68</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>68</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>70</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>70</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>71</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>71</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>72</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>72</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>73</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>155</int:fieldId>
   <int:id>4</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>75</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>148</int:fieldId>
   <int:id>5</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>75</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>75</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>75</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>155</int:fieldId>
   <int:id>4</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>76</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>148</int:fieldId>
   <int:id>5</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>76</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>76</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>76</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>77</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>80</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>155</int:fieldId>
   <int:id>4</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>148</int:fieldId>
   <int:id>5</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>86</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>86</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>87</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>87</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>155</int:fieldId>
   <int:id>4</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>148</int:fieldId>
   <int:id>5</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>91</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>91</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>92</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>92</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>93</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>93</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>155</int:fieldId>
   <int:id>4</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>94</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>148</int:fieldId>
   <int:id>5</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>94</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>94</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>94</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>95</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>95</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>96</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>96</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>97</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>97</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>98</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>99</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>100</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>100</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>101</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>101</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>106</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>109</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>113</unsignedLong:rowKey>
  </trait>
 </traits>
</bag>
